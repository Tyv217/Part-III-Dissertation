@InProceedings{cbm,
  title = 	 {Concept Bottleneck Models},
  author =       {Koh, Pang Wei and Nguyen, Thao and Tang, Yew Siang and Mussmann, Stephen and Pierson, Emma and Kim, Been and Liang, Percy},
  booktitle = 	 {Proceedings of the 37th International Conference on Machine Learning},
  pages = 	 {5338--5348},
  year = 	 {2020},
  editor = 	 {III, Hal Daum√© and Singh, Aarti},
  volume = 	 {119},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {13--18 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v119/koh20a/koh20a.pdf},
  url = 	 {https://proceedings.mlr.press/v119/koh20a.html},
  abstract = 	 {We seek to learn models that we can interact with using high-level concepts: if the model did not think there was a bone spur in the x-ray, would it still predict severe arthritis? State-of-the-art models today do not typically support the manipulation of concepts like "the existence of bone spurs", as they are trained end-to-end to go directly from raw input (e.g., pixels) to output (e.g., arthritis severity). We revisit the classic idea of first predicting concepts that are provided at training time, and then using these concepts to predict the label. By construction, we can intervene on these concept bottleneck models by editing their predicted concept values and propagating these changes to the final prediction. On x-ray grading and bird identification, concept bottleneck models achieve competitive accuracy with standard end-to-end models, while enabling interpretation in terms of high-level clinical concepts ("bone spurs") or bird attributes ("wing color"). These models also allow for richer human-model interaction: accuracy improves significantly if we can correct model mistakes on concepts at test time.}
}

@inproceedings{
intcem,
title={Learning to Receive Help: Intervention-Aware Concept Embedding Models},
author={Mateo Espinosa Zarlenga and Katherine M. Collins and Krishnamurthy Dj Dvijotham and Adrian Weller and Zohreh Shams and Mateja Jamnik},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
year={2023},
url={https://openreview.net/forum?id=4ImZxqmT1K}
}

@inproceedings{
cem,
title={Concept Embedding Models},
author={Mateo Espinosa Zarlenga and Pietro Barbiero and Gabriele Ciravegna and Giuseppe Marra and Francesco Giannini and Michelangelo Diligenti and Zohreh Shams and Frederic Precioso and Stefano Melacci and Adrian Weller and Pietro Lio and Mateja Jamnik},
booktitle={Advances in Neural Information Processing Systems},
editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
year={2022},
url={https://openreview.net/forum?id=HXCPA2GXf_}
}

@book{rl,
author = {Sutton, Richard S. and Barto, Andrew G.},
title = {Reinforcement Learning: An Introduction},
year = {2018},
isbn = {0262039249},
publisher = {A Bradford Book},
address = {Cambridge, MA, USA},
abstract = {The significantly expanded and updated new edition of a widely used text on reinforcement learning, one of the most active research areas in artificial intelligence. Reinforcement learning, one of the most active research areas in artificial intelligence, is a computational approach to learning whereby an agent tries to maximize the total amount of reward it receives while interacting with a complex, uncertain environment. In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the field's key ideas and algorithms. This second edition has been significantly expanded and updated, presenting new topics and updating coverage of other topics. Like the first edition, this second edition focuses on core online learning algorithms, with the more mathematical material set off in shaded boxes. Part I covers as much of reinforcement learning as possible without going beyond the tabular case for which exact solutions can be found. Many algorithms presented in this part are new to the second edition, including UCB, Expected Sarsa, and Double Learning. Part II extends these ideas to function approximation, with new sections on such topics as artificial neural networks and the Fourier basis, and offers expanded treatment of off-policy learning and policy-gradient methods. Part III has new chapters on reinforcement learning's relationships to psychology and neuroscience, as well as an updated case-studies chapter including AlphaGo and AlphaGo Zero, Atari game playing, and IBM Watson's wagering strategy. The final chapter discusses the future societal impacts of reinforcement learning.}
}

@article{coop,
author = {Chauhan, Kushal and Tiwari, Rishabh and Freyberg, Jan and Shenoy, Pradeep and Dvijotham, Krishnamurthy},
year = {2023},
month = {06},
pages = {5948-5955},
title = {Interactive Concept Bottleneck Models},
volume = {37},
journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
doi = {10.1609/aaai.v37i5.25736}
}

@INPROCEEDINGS{afa,
  author={Melville, P. and Saar-Tsechansky, M. and Provost, F. and Mooney, R.},
  booktitle={Fourth IEEE International Conference on Data Mining (ICDM'04)}, 
  title={Active feature-value acquisition for classifier induction}, 
  year={2004},
  volume={},
  number={},
  pages={483-486},
  keywords={Costs;Predictive models;Sampling methods;Design for experiments;Current measurement;Data mining},
  doi={10.1109/ICDM.2004.10075}}

  
@InProceedings{gsmrl,
  title = 	 {Active Feature Acquisition with Generative Surrogate Models},
  author =       {Li, Yang and Oliva, Junier},
  booktitle = 	 {Proceedings of the 38th International Conference on Machine Learning},
  pages = 	 {6450--6459},
  year = 	 {2021},
  editor = 	 {Meila, Marina and Zhang, Tong},
  volume = 	 {139},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {18--24 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v139/li21p/li21p.pdf},
  url = 	 {https://proceedings.mlr.press/v139/li21p.html},
  abstract = 	 {Many real-world situations allow for the acquisition of additional relevant information when making an assessment with limited or uncertain data. However, traditional ML approaches either require all features to be acquired beforehand or regard part of them as missing data that cannot be acquired. In this work, we consider models that perform active feature acquisition (AFA) and query the environment for unobserved features to improve the prediction assessments at evaluation time. Our work reformulates the Markov decision process (MDP) that underlies the AFA problem as a generative modeling task and optimizes a policy via a novel model-based approach. We propose learning a generative surrogate model (GSM) that captures the dependencies among input features to assess potential information gain from acquisitions. The GSM is leveraged to provide intermediate rewards and auxiliary information to aid the agent navigate a complicated high-dimensional action space and sparse rewards. Furthermore, we extend AFA in a task we coin active instance recognition (AIR) for the unsupervised case where the target variables are the unobserved features themselves and the goal is to collect information for a particular instance in a cost-efficient way. Empirical results demonstrate that our approach achieves considerably better performance than previous state of the art methods on both supervised and unsupervised tasks.}
}

@proceedings {cbm-hybrid,
	title = {Promises and Pitfalls of Black-Box Concept Learning Models},
	journal = {proceeding at the  International Conference on Machine Learning: Workshop on Theoretic Foundation, Criticism, and Application Trend of Explainable AI,},
	volume = {1},
	year = {2021},
	pages = {1-13},
	author = {A. Mahinpei and J. Clark and I. Lage and Doshi-Velez, F. and P. WeiWei}
}

@misc{acflow,
      title={Flow Models for Arbitrary Conditional Likelihoods}, 
      author={Yang Li and Shoaib Akbar and Junier B. Oliva},
      year={2020},
      eprint={1909.06319},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}