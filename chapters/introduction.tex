\documentclass[../main.tex]{subfiles}
\begin{document}
\chapter{Introduction}
\label{firstcontentpage}
Machine Learning models are universal approximation solutions to problems
and have been viewed and used traditionally as “black-box” solutions, 
where users simply query the model and receive an answer to the problem without 
necessarily knowing the exact reasoning process behind it. Over the past decade,
the increased application of ML models along with this “black-box” property has
raised many concerns, especially in areas where decisions made are critical to
human safety, such as in medicine or automated driving. To increase
interpretability, researchers developed Concept Bottleneck Models (CBMs) that 
predicts a set of human-interpretable concepts from input, and then uses the
predicted concepts to predict labels. This increases the interpretability of the model 
as humans
can understand the basis of the machine learning model predictions via the high-level 
intermediate concepts that the model is trained to predict. 

Another 
additional benefit of these types of machine-learning models is that when used in
practice, experts can modify the intermediate predicted concepts which can
lead to generating more accurate final predictions, hereafter these modifications are
referred to as interventions.
Given the costs associated with querying experts to intervene,
determining the order of concepts to intervene on to maximize 
the accuracy of the model given a limited budget, becomes an interesting problem.
This project focuses specifically on trying to solve this question using Reinforcement 
Learning and Surrogate models to model conditional probabilities. 
The end goal of this project is to be able to train RL models that will be able to 
produce non-greedy (or simply greedy, but more optimal) policies that can outperform 
existing greedy policy approaches. 

\end{document}